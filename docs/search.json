[
  {
    "objectID": "demo_ei.html",
    "href": "demo_ei.html",
    "title": "Introduction to Equivariant Imaging",
    "section": "",
    "text": "Train a neural network to solve an image inpainting inverse problem, using perspective-EI and the deepinv library.\n\nimport deepinv as dinv\n\n\n\ntorch imports\nimport torch\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import Compose, ToTensor, CenterCrop, Resize\nfrom torchvision.datasets.utils import download_and_extract_archive\n\n\nDefine inpainting experiment to reconstruct images from images masked with a random mask:\n\nphysics = dinv.physics.Inpainting((3, 256, 256), mask=0.6, device=\"cpu\")\n\nLoad Urban100 dataset of natural urban scenes:\n\n\nDownload dataset from HuggingFace\ndownload_and_extract_archive(\n    \"https://huggingface.co/datasets/eugenesiow/Urban100/resolve/main/data/Urban100_HR.tar.gz?download=true\",\n    \"Urban100\",\n    filename=\"Urban100_HR.tar.gz\",\n    md5=\"65d9d84a34b72c6f7ca1e26a12df1e4c\"\n)\n\n\n\ntrain_dataset, test_dataset = random_split(\n    ImageFolder(\"Urban100\", transform=Compose([ToTensor(), Resize(256), CenterCrop(256)])),\n    (0.8, 0.2)\n    )\n    \ntrain_dataloader, test_dataloader = DataLoader(train_dataset, shuffle=True), DataLoader(test_dataset)\n\nAs these scenes are imaged with a camera free to move and rotate in the world, we can impose perspective invariance on the unknown image set \\(x\\in X\\). Define measurement consistency and EI losses:\n\ntransform = dinv.transform.Homography(theta_max=10)\n\nlosses = [\n    dinv.loss.MCLoss(), \n    dinv.loss.EILoss(transform)\n]\n\nFor training, use a small UNet for the model with Adam optimizer:\n\nmodel = dinv.models.UNet(\n    in_channels=3, \n    out_channels=3,\n    scales=2,\n    circular_padding=True,\n    batch_norm=False\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)\n\nTrain the model using deepinvâ€™s Trainer:\n\nmodel = dinv.Trainer(\n    model=model,\n    physics=physics,\n    online_measurements=True,\n    train_dataloader=train_dataloader,\n    eval_dataloader=test_dataloader,\n    epochs=1,\n    losses=losses,\n    optimizer=optimizer,\n    verbose=True,\n    show_progress_bar=False,\n    save_path=None,\n    device=\"cpu\"\n).train()\n\nThe model has 444867 trainable parameters\nEval epoch 0: PSNR=10.078\nTrain epoch 0: MCLoss=0.002, EILoss=0.021, TotalLoss=0.023, PSNR=15.948\n\n\nShow results of a pretrained model trained using a larger UNet for 40 epochs:\n\n\nLoad pretrained model from HuggingFace\nmodel = dinv.models.UNet(\n    in_channels=3, \n    out_channels=3,\n    scales=3,\n    circular_padding=True,\n    batch_norm=False\n)\n\nckpt = torch.hub.load_state_dict_from_url(\n    dinv.models.utils.get_weights_url(\"ei\", \"Urban100_inpainting_homography_model.pth\"),\n    map_location=\"cpu\",\n)\n\nmodel.load_state_dict(ckpt[\"state_dict\"])\n\n\n&lt;All keys matched successfully&gt;\n\n\n\nx, _ = next(iter(train_dataloader))\ny = physics(x)\nx_hat = model(y)\n\ndinv.utils.plot([x, y, x_hat], [\"x\", \"y\", \"reconstruction\"])"
  }
]